{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 479
    },
    "colab_type": "code",
    "id": "1ttuirSPS8eP",
    "outputId": "0d477eff-af4f-4f31-f17a-14f7233a0212"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchtext==0.6 in c:\\users\\nithy\\anaconda3\\lib\\site-packages (0.6.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\nithy\\anaconda3\\lib\\site-packages (from torchtext==0.6) (4.46.0)\n",
      "Requirement already satisfied: requests in c:\\users\\nithy\\anaconda3\\lib\\site-packages (from torchtext==0.6) (2.22.0)\n",
      "Requirement already satisfied: torch in c:\\users\\nithy\\anaconda3\\lib\\site-packages (from torchtext==0.6) (1.5.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\nithy\\anaconda3\\lib\\site-packages (from torchtext==0.6) (1.16.5)\n",
      "Requirement already satisfied: six in c:\\users\\nithy\\anaconda3\\lib\\site-packages (from torchtext==0.6) (1.12.0)\n",
      "Collecting sentencepiece (from torchtext==0.6)\n",
      "  Downloading https://files.pythonhosted.org/packages/78/c7/fb817b7f0e8a4df1b1973a8a66c4db6fe10794a679cb3f39cd27cd1e182c/sentencepiece-0.1.91-cp37-cp37m-win_amd64.whl (1.2MB)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\users\\nithy\\anaconda3\\lib\\site-packages (from requests->torchtext==0.6) (2.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\nithy\\anaconda3\\lib\\site-packages (from requests->torchtext==0.6) (1.24.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\nithy\\anaconda3\\lib\\site-packages (from requests->torchtext==0.6) (2019.9.11)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\nithy\\anaconda3\\lib\\site-packages (from requests->torchtext==0.6) (3.0.4)\n",
      "Requirement already satisfied: future in c:\\users\\nithy\\anaconda3\\lib\\site-packages (from torch->torchtext==0.6) (0.18.2)\n",
      "Installing collected packages: sentencepiece\n",
      "Successfully installed sentencepiece-0.1.91\n"
     ]
    }
   ],
   "source": [
    "# Run onluy the first time!\n",
    "# from pyunpack import Archive\n",
    "# Archive('Images.zip').extractall('Assignment4_Images')\n",
    "!pip install torchtext==0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "lgMV2OMJS8eT",
    "outputId": "de3ba038-45d7-4949-9024-2551ebc41fcd"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import tarfile\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "from torch.utils.data import Dataset, DataLoader, ConcatDataset, random_split\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.decomposition import PCA\n",
    "from io import StringIO\n",
    "from PIL import Image\n",
    "from torchtext.vocab import GloVe\n",
    "from torchtext.data import Field\n",
    "from torchtext.data.metrics import bleu_score\n",
    "import torchtext\n",
    "from torchtext.data import get_tokenizer\n",
    "import pdb\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "kSKax7aBS8eX",
    "outputId": "141b0976-beb8-40e1-bbcb-f2962585f47b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "beGr3RXYS8ec"
   },
   "outputs": [],
   "source": [
    "class DatasetClass(Dataset):\n",
    "    \n",
    "    def __init__(self, folder, image_list, captions):\n",
    "        \n",
    "        self.folder = folder\n",
    "        self.captions = captions\n",
    "        self.size = 5*len(image_list)\n",
    "        self.image_list = []\n",
    "        for image in image_list:\n",
    "            all_images = [image + '#' + str(i) for i in range(5)]\n",
    "            self.image_list.extend(all_images)\n",
    "        \n",
    "    def __getitem__(self, idx):     \n",
    "        \n",
    "        image_name = self.image_list[idx]\n",
    "        caption = self.captions.loc[image_name, 'Caption']\n",
    "        img = Image.open(self.folder + image_name[:-2]).resize((227, 227))\n",
    "        trans = transforms.ToTensor()\n",
    "        return trans(img), caption\n",
    "      \n",
    "    def __len__(self):\n",
    "        \n",
    "        return self.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BZFjhoHoS8ef"
   },
   "outputs": [],
   "source": [
    "def train_test_loader(directory, image_list, captions, train_fraction=0.8, num_workers=0, batch_size=32):\n",
    "\n",
    "    dataset = DatasetClass(directory, image_list, captions)\n",
    "    \n",
    "    N = dataset.size\n",
    "    train_size = int(N*train_fraction)\n",
    "    test_size = N - train_size\n",
    "\n",
    "    train_data, test_data = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "\n",
    "    trainloader = DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "    testloader = DataLoader(test_data, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "    \n",
    "    return trainloader, testloader, train_size, test_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J1SV7dwrS8ei"
   },
   "outputs": [],
   "source": [
    "# with open('/content/drive/My Drive/captions.txt') as f:\n",
    "#     captions = pd.read_csv(StringIO(f.read()), sep='\\t', header=None, names=['Image', 'Caption']).set_index('Image', drop=True)\n",
    "    \n",
    "# with open('/content/drive/My Drive/image_names.txt') as f:\n",
    "#     names = list(map(lambda x: x.rstrip(), f.readlines()))\n",
    "\n",
    "with open('D:/_SEM8/DL/Assignment 4/captions.txt') as f:\n",
    "    captions = pd.read_csv(StringIO(f.read()), sep='\\t', header=None, names=['Image', 'Caption']).set_index('Image', drop=True)\n",
    "    \n",
    "with open('D:/_SEM8/DL/Assignment 4/image_names.txt') as f:\n",
    "    names = list(map(lambda x: x.rstrip(), f.readlines()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Jf3Ual9sS8el"
   },
   "outputs": [],
   "source": [
    "# trainloader, testloader, train_size, test_size = train_test_loader(directory='/content/drive/My Drive/Assignment4_Data/Images/', image_list=names, captions=captions)\n",
    "\n",
    "trainloader, testloader, train_size, test_size = train_test_loader(directory='D:/_SEM8/DL/Assignment 4/Assignment4_Images/Images/', image_list=names, captions=captions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IbRgcoATS8eo"
   },
   "source": [
    "#### GloVe Representation\n",
    "\n",
    "Available GloVe Representations: \n",
    "\n",
    "1. glove.42B.300d \n",
    "2. glove.840B.300d \n",
    "3. glove.twitter.27B.25d \n",
    "4. glove.twitter.27B.50d \n",
    "5. glove.twitter.27B.100d \n",
    "6. glove.twitter.27B.200d \n",
    "7. glove.6B.50d \n",
    "8. glove.6B.100d \n",
    "9. glove.6B.200d \n",
    "10. glove.6B.300d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wcB9kNIWS8ep"
   },
   "outputs": [],
   "source": [
    "embedding_glove = GloVe(name='6B', dim=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HehTL29QS8et"
   },
   "outputs": [],
   "source": [
    "text_field = Field(tokenize='basic_english', lower=True, eos_token='eos', init_token='sos')\n",
    "preprocessed_text = captions['Caption'].apply(lambda x: text_field.preprocess(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1fMAh6C0S8ew"
   },
   "outputs": [],
   "source": [
    "text_field.build_vocab(preprocessed_text, vectors=embedding_glove)\n",
    "embedding_trained = text_field.vocab.vectors[2:, :]\n",
    "# embedding_trained = nn.Embedding.from_pretrained(text_field.vocab.vectors[2:, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W4W6SHpmS8ey"
   },
   "outputs": [],
   "source": [
    "vocab_tokens = np.array(text_field.vocab.itos)[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "esNOLYw0S8e1"
   },
   "outputs": [],
   "source": [
    "class NetVLAD(nn.Module):\n",
    "    \n",
    "    def __init__(self, k):\n",
    "        super(NetVLAD, self).__init__()\n",
    "        \n",
    "        # CNN\n",
    "        self.c1 = nn.Conv2d(3, 96, 11, stride=4)\n",
    "        self.mp1 = nn.MaxPool2d(3, stride=2)\n",
    "        self.c2 = nn.Conv2d(96, 256, 5)\n",
    "        self.mp2 = nn.MaxPool2d(3, stride=2)\n",
    "        self.c3 = nn.Conv2d(256, 384, 3)\n",
    "        self.c4 = nn.Conv2d(384, 384, 3)\n",
    "        self.c5 = nn.Conv2d(384, 256, 3, stride=3)\n",
    "\n",
    "        # NetVLAD\n",
    "        self.K = k\n",
    "        self.nv_conv = nn.Conv2d(256, k, 1)\n",
    "        self.nv_soft_ass = nn.Softmax2d()\n",
    "\n",
    "        # NetVLAD Parameter\n",
    "        self.c = nn.Parameter(torch.Tensor(self.K, 256))\n",
    "        \n",
    "        # Flatten to get h\n",
    "        self.flat = nn.Flatten(1, -1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        # CNN\n",
    "        x = self.mp1(F.relu(self.c1(x)))\n",
    "        x = self.mp2(F.relu(self.c2(x)))\n",
    "        x = F.relu(self.c5(F.relu(self.c4(F.relu(self.c3(x))))))\n",
    "\n",
    "        self.z_pre = x.flatten(2, 3)\n",
    "\n",
    "        # NetVLAD Step 1\n",
    "        a = self.nv_soft_ass(self.nv_conv(x))\n",
    "\n",
    "        # NetVLAD Step 2\n",
    "        for k in range(self.K):\n",
    "            a_k = a[:, k, :, :]\n",
    "            c_k = self.c[k, :]\n",
    "            temp = (x - c_k.reshape(1, -1, 1, 1))*a_k.unsqueeze(1)\n",
    "            z_k = torch.sum(temp, axis=(2, 3))\n",
    "            if k==0:\n",
    "                Z = z_k.unsqueeze(1)\n",
    "            else:\n",
    "                Z = torch.cat((Z, z_k.unsqueeze(1)), 1)\n",
    "        \n",
    "        # Flatten\n",
    "        Z = self.flat(Z)\n",
    "        \n",
    "#         print(Z.shape)\n",
    "\n",
    "        return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8euzqlbqesoo"
   },
   "outputs": [],
   "source": [
    "cnn_model = NetVLAD(1).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0Hu4cFa3dyWx"
   },
   "outputs": [],
   "source": [
    "for data in trainloader:\n",
    "    X = data[0].to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        _ = cnn_model(X)\n",
    "        Z_pre = cnn_model.z_pre\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 573
    },
    "colab_type": "code",
    "id": "XtAi3kiJe9P4",
    "outputId": "f3de097e-f3d2-45fb-9bbc-a0d93314e719"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sh_full = np.zeros(9)\n",
    "inertia_full = np.zeros(10)\n",
    "\n",
    "for i in range(Z_pre.shape[0]):\n",
    "    inertia = []\n",
    "    sh_mean = []\n",
    "    for n_clusters in range(1, 11):\n",
    "        X = Z_pre[i, :, :].cpu().numpy()\n",
    "        model = KMeans(n_clusters).fit(X)\n",
    "        inertia.append(model.inertia_)\n",
    "\n",
    "    if n_clusters != 1:\n",
    "        cluster_labels = KMeans(n_clusters).fit_predict(X)\n",
    "        sh_mean.append(silhouette_score(X, cluster_labels))\n",
    "\n",
    "    sh_full += np.array(sh_mean)\n",
    "    inertia_full += np.array(inertia)\n",
    "\n",
    "plt.plot(range(2, 11), sh_full)\n",
    "plt.title('Average Silhouette Coefficient (Sum over a batch)')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('Mean Silhouette Coefficient')\n",
    "plt.show()\n",
    "plt.plot(range(1, 11), inertia_full)\n",
    "plt.title('Elbow Plot (Sum over a batch)')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('Intertia')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pCFgFv3JS8e5"
   },
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "\n",
    "    def __init__(self, embed_size, hidden_size, output_size, embedding_pre_trained):\n",
    "        \n",
    "        super(RNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        # Pre-trained Word Embedding of all the words is used\n",
    "        self.embedding = nn.Embedding.from_pretrained(embedding_pre_trained)\n",
    "        \n",
    "        # Input to the RNN is word embeddings of a word\n",
    "        self.rnn = nn.RNN(input_size=embed_size, hidden_size=hidden_size) \n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)  \n",
    "        \n",
    "    def forward(self, input_vec, hidden_vec):\n",
    "        '''\n",
    "        Parameters:\n",
    "        ------------\n",
    "        input_vec  - tensor of index of word/token. Example: torch.LongTensor([[0]]) for sos_token\n",
    "        hidden_vec - train_image or output from previous RNN cell\n",
    "        '''\n",
    "#         try:\n",
    "\n",
    "        embedded_input_vec = self.embedding(input_vec)\n",
    "        output_vec, hidden_vec = self.rnn(embedded_input_vec, hidden_vec)\n",
    "        output_vec = self.softmax(self.out(output_vec[0]))\n",
    "#         except:\n",
    "#             pdb.set_trace()\n",
    "\n",
    "        return output_vec, hidden_vec      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WylTwrZ7S8e7"
   },
   "outputs": [],
   "source": [
    "# class LSTM(nn.Module):\n",
    "\n",
    "#     def __init__(self, embed_size, hidden_size, output_size, embedding_pre_trained):\n",
    "        \n",
    "#         super(LSTM, self).__init__()\n",
    "#         self.hidden_size = hidden_size\n",
    "        \n",
    "#         # Pre-trained Word Embedding of all the words is used\n",
    "#         self.embedding = nn.Embedding.from_pretrained(embedding_pre_trained)\n",
    "        \n",
    "#         # Input to the RNN is word embeddings of a word\n",
    "#         self.lstm = nn.LSTM(input_size=embed_size, hidden_size=hidden_size) \n",
    "#         self.out = nn.Linear(hidden_size, output_size)\n",
    "#         self.softmax = nn.LogSoftmax(dim=1)  \n",
    "        \n",
    "#     def forward(self, input_vec, hidden_vec):\n",
    "#         '''\n",
    "#         Parameters:\n",
    "#         ------------\n",
    "#         input_vec  - tensor of index of word/token. Example: torch.LongTensor([[0]]) for sos_token\n",
    "#         hidden_vec - train_image or output from previous RNN cell\n",
    "#         '''\n",
    "#         embedded_input_vec = self.embedding(input_vec)\n",
    "#         output_vec, hidden_vec = self.lstm(embedded_input_vec, hidden_vec)\n",
    "#         output_vec = self.softmax(self.out(output_vec[0]))\n",
    "#         return output_vec, hidden_vec      \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ftndegJtS8e-"
   },
   "outputs": [],
   "source": [
    "def train_one_image(train_image, image_caption, encoder_obj, decoder_obj, encoder_optim, decoder_optim, loss_func, vocab_tokens):\n",
    "    '''\n",
    "    Parameters:\n",
    "    -----------\n",
    "    train_image     - Images stored in batches using DataLoader\n",
    "    image_caption   - Caption of the image (in the same word embedding representation used in )\n",
    "\n",
    "    \n",
    "    '''\n",
    "    # Start of sentence and End of Sentence token\n",
    "    eos_token = np.argwhere(vocab_tokens=='eos').item()\n",
    "    sos_token = np.argwhere(vocab_tokens=='sos').item()\n",
    "    \n",
    "    # Length of the image caption\n",
    "    caption_length = len(image_caption)\n",
    "    \n",
    "    # Setting gradients from previous backpropagation to zero\n",
    "    encoder_optim.zero_grad()\n",
    "    decoder_optim.zero_grad()\n",
    "    \n",
    "    # TO BE CHECKED!!!!!!!!!!!!!!\n",
    "    encoder_output = encoder_obj(train_image).view(1, 1, -1) \n",
    "    print(encoder_output)\n",
    "    \n",
    "    decoder_input = torch.tensor([[sos_token]], device=device)  ## This is converted into an embedding withing the decoder class\n",
    "    decoder_hidden = encoder_output\n",
    "    decoder_hidden_size = decoder_hidden.shape[-1]\n",
    "\n",
    "    try:\n",
    "    \n",
    "        loss = 0\n",
    "        for i in range(caption_length):\n",
    "            decoder_output, decoder_hidden = decoder_obj(decoder_input, decoder_hidden) \n",
    "            max_val, max_ind = decoder_output.topk(1)  # Choosing the word with maximum probability \n",
    "            decoder_input = max_ind  #.squeeze().detach()                     \n",
    "            loss += loss_func(decoder_output, torch.tensor([np.argwhere(vocab_tokens == image_caption[i]).item()]).to(device))\n",
    "            if decoder_input.item() == eos_token:\n",
    "                break\n",
    "#             print(loss)\n",
    "        loss.backward()\n",
    "        encoder_optim.step()\n",
    "        decoder_optim.step()\n",
    "    except:\n",
    "        pdb.set_trace()\n",
    "\n",
    "    return loss.item()/caption_length\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nJjH_4T6S8fA"
   },
   "outputs": [],
   "source": [
    "def train(lr, trainloader_images, train_images_size, encoder_obj, decoder_obj, preprocessed_text, captions, vocab_tokens):\n",
    "    \n",
    "    loss_func = nn.NLLLoss()\n",
    "\n",
    "    tokenizer = get_tokenizer(\"basic_english\")\n",
    "    \n",
    "    encoder_optim = optim.SGD(encoder_obj.parameters(), lr=lr)\n",
    "    decoder_optim = optim.SGD(decoder_obj.parameters(), lr=lr)\n",
    "    \n",
    "    old_loss = np.inf\n",
    "    epoch = 0\n",
    "    losses = []\n",
    "    while True:\n",
    "        new_loss = 0\n",
    "        epoch += 1\n",
    "        batch = 0 \n",
    "        for data in trainloader_images:\n",
    "            batch += 1\n",
    "            images, captions = data[0].to(device), data[1]\n",
    "            bs = images.shape[0]\n",
    "\n",
    "            for i in range(bs):\n",
    "                train_image = images[i].view(1, images.shape[1], images.shape[2], images.shape[3])\n",
    "                image_caption = tokenizer(captions[i])\n",
    "                image_caption.append('eos')\n",
    "                new_loss += train_one_image(train_image, image_caption, encoder_obj, decoder_obj, encoder_optim, decoder_optim, loss_func, vocab_tokens)\n",
    "            \n",
    "#             print('Batch {0}'.format(batch))\n",
    "            \n",
    "        new_loss = new_loss/train_images_size\n",
    "        \n",
    "        print('Epoch {0}: Loss = {1}, Rel loss = {2}'.format(epoch, new_loss, abs(new_loss-old_loss)/new_loss))\n",
    "        losses.append(new_loss)\n",
    "\n",
    "        if abs(new_loss-old_loss)/new_loss < 1e-5:\n",
    "            print('Converged')\n",
    "            return losses\n",
    "\n",
    "        old_loss = new_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5\n",
    "encoder_obj = NetVLAD(k).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZnMma46TS8fC",
    "outputId": "f8a844c5-9a55-4b5c-d4f9-79359407fde4",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[nan, nan, nan,  ..., nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([[[nan, nan, nan,  ..., nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([[[nan, nan, nan,  ..., nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([[[nan, nan, nan,  ..., nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([[[nan, nan, nan,  ..., nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([[[nan, nan, nan,  ..., nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([[[nan, nan, nan,  ..., nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([[[nan, nan, nan,  ..., nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([[[nan, nan, nan,  ..., nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([[[nan, nan, nan,  ..., nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([[[nan, nan, nan,  ..., nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([[[nan, nan, nan,  ..., nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([[[nan, nan, nan,  ..., nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([[[nan, nan, nan,  ..., nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([[[nan, nan, nan,  ..., nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([[[nan, nan, nan,  ..., nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([[[nan, nan, nan,  ..., nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([[[nan, nan, nan,  ..., nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([[[nan, nan, nan,  ..., nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([[[nan, nan, nan,  ..., nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([[[nan, nan, nan,  ..., nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([[[nan, nan, nan,  ..., nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([[[nan, nan, nan,  ..., nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([[[nan, nan, nan,  ..., nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([[[nan, nan, nan,  ..., nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([[[nan, nan, nan,  ..., nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([[[nan, nan, nan,  ..., nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([[[nan, nan, nan,  ..., nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([[[nan, nan, nan,  ..., nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([[[nan, nan, nan,  ..., nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([[[nan, nan, nan,  ..., nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([[[nan, nan, nan,  ..., nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([[[nan, nan, nan,  ..., nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "tensor([[[nan, nan, nan,  ..., nan, nan, nan]]], device='cuda:0',\n",
      "       grad_fn=<ViewBackward>)\n",
      "> <ipython-input-22-e87bcb82d03a>(46)train_one_image()\n",
      "-> return loss.item()/caption_length\n",
      "(Pdb) exit\n"
     ]
    },
    {
     "ename": "BdbQuit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mBdbQuit\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-378b96028d03>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdecoder_obj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRNN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0membed_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecoder_hidden_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecoder_output_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0membedding_trained\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mlosses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.001\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoder_obj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecoder_obj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreprocessed_text\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvocab_tokens\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-19-9020b9c8dbf0>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(lr, trainloader_images, train_images_size, encoder_obj, decoder_obj, preprocessed_text, captions, vocab_tokens)\u001b[0m\n\u001b[0;32m     24\u001b[0m                 \u001b[0mimage_caption\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcaptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m                 \u001b[0mimage_caption\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'eos'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m                 \u001b[0mnew_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mtrain_one_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_image\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage_caption\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoder_obj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecoder_obj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoder_optim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecoder_optim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvocab_tokens\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;31m#             print('Batch {0}'.format(batch))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-22-e87bcb82d03a>\u001b[0m in \u001b[0;36mtrain_one_image\u001b[1;34m(train_image, image_caption, encoder_obj, decoder_obj, encoder_optim, decoder_optim, loss_func, vocab_tokens)\u001b[0m\n\u001b[0;32m     44\u001b[0m         \u001b[0mpdb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mcaption_length\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-22-e87bcb82d03a>\u001b[0m in \u001b[0;36mtrain_one_image\u001b[1;34m(train_image, image_caption, encoder_obj, decoder_obj, encoder_optim, decoder_optim, loss_func, vocab_tokens)\u001b[0m\n\u001b[0;32m     44\u001b[0m         \u001b[0mpdb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mcaption_length\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\bdb.py\u001b[0m in \u001b[0;36mtrace_dispatch\u001b[1;34m(self, frame, event, arg)\u001b[0m\n\u001b[0;32m     86\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;31m# None\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'line'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_line\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'call'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\bdb.py\u001b[0m in \u001b[0;36mdispatch_line\u001b[1;34m(self, frame)\u001b[0m\n\u001b[0;32m    111\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop_here\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbreak_here\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muser_line\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 113\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mquitting\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mraise\u001b[0m \u001b[0mBdbQuit\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    114\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrace_dispatch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mBdbQuit\u001b[0m: "
     ]
    }
   ],
   "source": [
    "embed_size = embedding_trained.shape[1]\n",
    "decoder_output_size = embedding_trained.shape[0]\n",
    "decoder_hidden_size = 1280 ###(fix laterrrrrrrrrrrr)\n",
    "decoder_obj = RNN(embed_size, decoder_hidden_size, decoder_output_size, embedding_trained).to(device)\n",
    "\n",
    "losses = train(0.001, trainloader, train_size, encoder_obj, decoder_obj, preprocessed_text, captions, vocab_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7G2KN29uS8fF"
   },
   "outputs": [],
   "source": [
    "def evaluate(encoder_obj, decoder_obj, image, image_caption, vocab_tokens):\n",
    "    with torch.no_grad():\n",
    "\n",
    "        # Start of sentence and End of Sentence token\n",
    "        sos_token = np.argwhere(vocab_tokens=='sos').item()\n",
    "        eos_token = np.argwhere(vocab_tokens=='eos').item()\n",
    "\n",
    "        # Length of the image caption\n",
    "        caption_length = image_caption.size(0)\n",
    "\n",
    "\n",
    "        # TO BE CHECKED!!!!!!!!!!!!!!\n",
    "        encoder_output = encoder_obj(image).view(1, 1, -1)  \n",
    "        decoder_hidden_size = encoder_output.shape[-1]\n",
    "        \n",
    "        decoder_input = torch.tensor([[sos_token]], device=device)\n",
    "        decoder_hidden = encoder_output\n",
    "\n",
    "        output_caption = []\n",
    "        for i in range(caption_length):\n",
    "            decoder_output, decoder_hidden = decoder_obj(decoder_input, decoder_hidden) \n",
    "            max_val, max_ind = decoder_output.topk(1)  # Choosing the word with maximum probability \n",
    "            decoder_input = max_ind \n",
    "            loss += loss_func(decoder_output, image_caption[i])\n",
    "            if decoder_input.item() == eos_token:\n",
    "                output_caption.append('eos')\n",
    "                break\n",
    "            else:\n",
    "                output_caption.append(vocab_tokens[decoder_input.item()])\n",
    "        \n",
    "        print('Image caption: ', image_caption)\n",
    "        print('Predicted caption: ', output_caption)\n",
    "\n",
    "#         return bleu_score(image_caption, output_caption)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nCi7OWIyS8fI"
   },
   "source": [
    "### Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YnrTPAEaS8fJ"
   },
   "source": [
    "### Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oIJeqnwuS8fJ"
   },
   "outputs": [],
   "source": [
    "k = 1\n",
    "decoder_hidden_size =50\n",
    "\n",
    "encoder_obj = NetVLAD(k).to(device)\n",
    "\n",
    "embed_size = embedding_trained.weight.shape[1]\n",
    "decoder_output_size = embedding_trained.weight.shape[0]\n",
    "decoder_obj = LSTM(embed_size, decoder_hidden_size, decoder_output_size, embedding_trained).to(device)\n",
    "\n",
    "train(lr=0.01, trainloader, encoder_obj, decoder_obj)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Q1_Q2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
