{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "Q5(A4New).ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "LX6aW_yYsi2Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "4296e1f7-6df4-4453-fdda-13379ca34696"
      },
      "source": [
        "!pip install torchtext==0.6"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchtext==0.6 in /usr/local/lib/python3.6/dist-packages (0.6.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from torchtext==0.6) (0.1.91)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchtext==0.6) (1.15.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from torchtext==0.6) (4.41.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchtext==0.6) (1.5.1+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchtext==0.6) (1.18.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from torchtext==0.6) (2.23.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->torchtext==0.6) (0.16.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.6) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.6) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.6) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.6) (2.10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iF37RTfHsPDJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pdb\n",
        "import os\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xdY8Sim6sPDP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e26f02b8-3634-4f38-bafd-d4bd7ebeaaaa"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import TransformerEncoder, TransformerEncoderLayer, TransformerDecoder, TransformerDecoderLayer, Transformer\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import torch.optim as optim\n",
        "from torchtext.vocab import GloVe\n",
        "from torchtext.data import Field, BucketIterator\n",
        "from torchtext.data.metrics import bleu_score\n",
        "import spacy\n",
        "import math\n",
        "import pickle\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bq0c9sAtsPDS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ebd66609-1bb5-4d1c-db15-6875ea8d0a1f"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yoymO7dLsPDW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Reading files\n",
        "\n",
        "with open('/content/drive/My Drive/Assignment4_2/trainen.txt', encoding='utf8') as f:\n",
        "    eng_train = list(map(lambda x: x.rstrip(), f.readlines()))\n",
        "    \n",
        "with open('/content/drive/My Drive/Assignment4_2/trainta.txt', encoding='utf8') as f:\n",
        "    tamil_train = list(map(lambda x: x.rstrip(), f.readlines()))\n",
        "    \n",
        "with open('/content/drive/My Drive/Assignment4_2/deven.txt', encoding='utf8') as f:\n",
        "    eng_test = list(map(lambda x: x.rstrip(), f.readlines()))\n",
        "    \n",
        "with open('/content/drive/My Drive/Assignment4_2/devta.txt', encoding='utf8') as f:\n",
        "    tamil_test = list(map(lambda x: x.rstrip(), f.readlines()))\n",
        "\n",
        "embedding_glove = pickle.load(open('/content/drive/My Drive/Assignment4_2/glove.sav', 'rb'))\n",
        "\n",
        "# with open('trainen.txt', encoding='utf8') as f:\n",
        "#     eng_train = list(map(lambda x: x.rstrip(), f.readlines()))\n",
        "    \n",
        "# with open('trainta.txt', encoding='utf8') as f:\n",
        "#     tamil_train = list(map(lambda x: x.rstrip(), f.readlines()))\n",
        "    \n",
        "# with open('deven.txt', encoding='utf8') as f:\n",
        "#     eng_test = list(map(lambda x: x.rstrip(), f.readlines()))\n",
        "    \n",
        "# with open('devta.txt', encoding='utf8') as f:\n",
        "#     tamil_test = list(map(lambda x: x.rstrip(), f.readlines()))\n",
        "    \n",
        "# embedding_glove = GloVe(name='6B', dim=100)\n",
        "\n",
        "spacy_en = spacy.load('en_core_web_sm')\n",
        "\n",
        "def tokenize_en(text):\n",
        "    return [tok.text for tok in spacy_en.tokenizer(text)]\n",
        "\n",
        "stop_words = [',','.','?','!',')','(',':',']','[','$','#','&','%','--']\n",
        "ENG = Field(tokenize = tokenize_en, init_token='sos', eos_token = 'eos', lower=True, stop_words=stop_words)\n",
        "processed_eng_train = list(map(lambda x: ENG.preprocess(x), eng_train))\n",
        "processed_eng_test = list(map(lambda x: ENG.preprocess(x), eng_test))\n",
        "\n",
        "ENG.build_vocab(processed_eng_train, vectors=embedding_glove)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BcqEHd_usPDa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess(processed_eng):\n",
        "    \n",
        "    #function to return the numericalized version of the tokenized sentences\n",
        "    X = []\n",
        "    for tokenized_sentence in processed_eng:\n",
        "        int_sequence = [2]  #first element is the SOS token \n",
        "        for token in tokenized_sentence:\n",
        "            int_sequence.append(ENG.vocab.stoi[token])\n",
        "        int_sequence.append(3) #last element is the EOS token\n",
        "        X.append(int_sequence)\n",
        "    \n",
        "    return X\n",
        "\n",
        "# X_train and X_test are lists of lists with the integer sequences for a given sentence\n",
        "X_train = preprocess(processed_eng_train)\n",
        "X_test = preprocess(processed_eng_test)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37wFGsVUsPDd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "56f646da-5a69-4999-e243-d2d57fb16ba9"
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Same thing for Tamil sentences\n",
        "TAM = Tokenizer()\n",
        "TAM.fit_on_texts(tamil_train)\n",
        "Y_train = TAM.texts_to_sequences(tamil_train)\n",
        "Y_test = TAM.texts_to_sequences(tamil_test)\n",
        "\n",
        "#adding EOS token\n",
        "EOS = len(TAM.word_index)+2\n",
        "SOS = len(TAM.word_index)+1\n",
        "_ = [y.append(EOS) for y in Y_train]\n",
        "_ = [y.append(EOS) for y in Y_test]\n",
        "\n",
        "Y_train = pad_sequences(Y_train, padding='post', value=0, maxlen=30)\n",
        "Y_test = pad_sequences(Y_test, padding='post', value=0, maxlen=30)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V7WcYdgBsPDj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# pre-padding the inputs with value 1, from the dictionary ENG.vocab.stoi\n",
        "X_train = pad_sequences(X_train, padding='pre', value=1, maxlen=55)\n",
        "X_test = pad_sequences(X_test, padding='pre', value=1, maxlen=55)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ULUue3n7sPDm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8dfccb57-a798-4f47-b0fc-28101a802c66"
      },
      "source": [
        "len(Y_test[0])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xe-q2cXVsPDo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "7433ff60-6d12-439e-c4e5-01d36978fb9b"
      },
      "source": [
        "source_vocab_size = len(ENG.vocab)\n",
        "target_vocab_size = len(TAM.word_index)+3\n",
        "print(source_vocab_size)\n",
        "print(target_vocab_size)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9724\n",
            "18671\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZOUOpensPDr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import Dataset, DataLoader, ConcatDataset, random_split\n",
        "\n",
        "class DatasetClass(Dataset):\n",
        "    \n",
        "    def __init__(self, source, target):\n",
        "        \n",
        "        self.source = source\n",
        "        self.target = target\n",
        "      \n",
        "    def __len__(self):\n",
        "        \n",
        "        return len(self.source)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        \n",
        "        return self.source[idx], self.target[idx]"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2D0NFvgZsPDv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_test_loader(source_train, target_train, source_test, target_test, num_workers=0, batch_size=32):\n",
        "\n",
        "    train_data = DatasetClass(source_train, target_train)\n",
        "    test_data = DatasetClass(source_test, target_test)\n",
        "\n",
        "    trainloader = DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
        "    testloader = DataLoader(test_data, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
        "    \n",
        "    return trainloader, testloader"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6R3XgLFsPDx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class PositionEncoding(nn.Module):\n",
        "\n",
        "    def __init__(self, d_model, dropout=0.1, max_len=55):\n",
        "        super(PositionEncoding, self).__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "        pos_enc = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "        # even columns use sin\n",
        "        pos_enc[:, 0::2] = torch.sin(position * div_term)\n",
        "        # odd columns use cos\n",
        "        pos_enc[:, 1::2] = torch.cos(position * div_term)\n",
        "        pos_enc = pos_enc.unsqueeze(0).transpose(0, 1)    # 55 x 1 x 100\n",
        "        print('pos_enc.shape', pos_enc.shape)\n",
        "        \n",
        "        # to prevent the optimiser from changing the position encodings\n",
        "        self.register_buffer('pos_enc', pos_enc)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.pos_enc[:x.size(0), :]\n",
        "        return self.dropout(x)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OEVYcVjMsPD1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Trans(nn.Module):\n",
        "    \n",
        "    def __init__(self, target_vocab_size, embed_size, num_heads, num_layers, dropout, ENG):\n",
        "        \n",
        "        super(Trans, self).__init__()\n",
        "        self.pos_encoder = PositionEncoding(embed_size, dropout)\n",
        "        self.encoder = nn.Embedding.from_pretrained(ENG.vocab.vectors)\n",
        "        self.transformer = nn.Transformer(embed_size, num_heads, num_layers, num_layers, dropout=dropout)\n",
        "        self.decoder = nn.Embedding(target_vocab_size, embed_size)\n",
        "        self.fc = nn.Linear(embed_size, target_vocab_size)\n",
        "        self.logsoftmax = nn.LogSoftmax(dim=1)\n",
        "        \n",
        "    def forward(self, src, trg):\n",
        "        \n",
        "        # src and trg will be 1-D tensors with size Ts and Tt\n",
        "        src = self.encoder(src)     # batch_size x Ts x 100\n",
        "        src = self.pos_encoder(src.transpose(0,1)) # Ts x batch_size x 100\n",
        "        trg = self.decoder(trg)     # batch_size x Tt x 100\n",
        "        trg = self.pos_encoder(trg.transpose(0,1)) # Tt x batch_size x 100\n",
        "        src_mask = (torch.tril(torch.ones(src.shape[0], src.shape[0])) == 0).to(device)\n",
        "        trg_mask = (torch.tril(torch.ones(trg.shape[0], trg.shape[0])) == 0).to(device)\n",
        "        output = self.transformer(src, trg, src_mask, trg_mask)\n",
        "        output = self.fc(output)  # output will now be Tt x batch_size x target_vocab_size\n",
        "        output = self.logsoftmax(output)\n",
        "        \n",
        "        return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xKCQvYtU5KKe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "output = torch.rand(3, 5, 10)\n",
        "out = nn.Softmax(dim=2)(output)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lFGgZPF85zrl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "2f91a320-5340-4e3a-efc0-d62f9554c19f"
      },
      "source": [
        "out[:, 1, :]"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0767, 0.1109, 0.0709, 0.1384, 0.1029, 0.0781, 0.0671, 0.1345, 0.1013,\n",
              "         0.1192],\n",
              "        [0.0728, 0.0674, 0.0872, 0.1636, 0.0696, 0.0767, 0.1741, 0.1151, 0.0737,\n",
              "         0.0997],\n",
              "        [0.0752, 0.0696, 0.0916, 0.1046, 0.1260, 0.1461, 0.0797, 0.0940, 0.1198,\n",
              "         0.0934]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uyvd61GisPD3",
        "colab_type": "code",
        "colab": {},
        "outputId": "775c0a1f-cdc0-4aa3-d177-a5af15eeed28"
      },
      "source": [
        "embed_size = 100\n",
        "num_heads = 4\n",
        "num_layers = 2\n",
        "dropout = 0.2\n",
        "trans_model = Trans(target_vocab_size, embed_size, num_heads, num_layers, dropout, ENG)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "pos_enc.shape torch.Size([55, 1, 100])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o46xMQ5DsPD5",
        "colab_type": "code",
        "colab": {},
        "outputId": "a19e385e-9c76-44f4-885a-1f003be6c8eb"
      },
      "source": [
        "trans_model.to(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Trans(\n",
              "  (pos_encoder): PositionEncoding(\n",
              "    (dropout): Dropout(p=0.2, inplace=False)\n",
              "  )\n",
              "  (encoder): Embedding(9723, 100)\n",
              "  (transformer): Transformer(\n",
              "    (encoder): TransformerEncoder(\n",
              "      (layers): ModuleList(\n",
              "        (0): TransformerEncoderLayer(\n",
              "          (self_attn): MultiheadAttention(\n",
              "            (out_proj): Linear(in_features=100, out_features=100, bias=True)\n",
              "          )\n",
              "          (linear1): Linear(in_features=100, out_features=2048, bias=True)\n",
              "          (dropout): Dropout(p=0.2, inplace=False)\n",
              "          (linear2): Linear(in_features=2048, out_features=100, bias=True)\n",
              "          (norm1): LayerNorm((100,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm2): LayerNorm((100,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout1): Dropout(p=0.2, inplace=False)\n",
              "          (dropout2): Dropout(p=0.2, inplace=False)\n",
              "        )\n",
              "        (1): TransformerEncoderLayer(\n",
              "          (self_attn): MultiheadAttention(\n",
              "            (out_proj): Linear(in_features=100, out_features=100, bias=True)\n",
              "          )\n",
              "          (linear1): Linear(in_features=100, out_features=2048, bias=True)\n",
              "          (dropout): Dropout(p=0.2, inplace=False)\n",
              "          (linear2): Linear(in_features=2048, out_features=100, bias=True)\n",
              "          (norm1): LayerNorm((100,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm2): LayerNorm((100,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout1): Dropout(p=0.2, inplace=False)\n",
              "          (dropout2): Dropout(p=0.2, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (norm): LayerNorm((100,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "    (decoder): TransformerDecoder(\n",
              "      (layers): ModuleList(\n",
              "        (0): TransformerDecoderLayer(\n",
              "          (self_attn): MultiheadAttention(\n",
              "            (out_proj): Linear(in_features=100, out_features=100, bias=True)\n",
              "          )\n",
              "          (multihead_attn): MultiheadAttention(\n",
              "            (out_proj): Linear(in_features=100, out_features=100, bias=True)\n",
              "          )\n",
              "          (linear1): Linear(in_features=100, out_features=2048, bias=True)\n",
              "          (dropout): Dropout(p=0.2, inplace=False)\n",
              "          (linear2): Linear(in_features=2048, out_features=100, bias=True)\n",
              "          (norm1): LayerNorm((100,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm2): LayerNorm((100,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm3): LayerNorm((100,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout1): Dropout(p=0.2, inplace=False)\n",
              "          (dropout2): Dropout(p=0.2, inplace=False)\n",
              "          (dropout3): Dropout(p=0.2, inplace=False)\n",
              "        )\n",
              "        (1): TransformerDecoderLayer(\n",
              "          (self_attn): MultiheadAttention(\n",
              "            (out_proj): Linear(in_features=100, out_features=100, bias=True)\n",
              "          )\n",
              "          (multihead_attn): MultiheadAttention(\n",
              "            (out_proj): Linear(in_features=100, out_features=100, bias=True)\n",
              "          )\n",
              "          (linear1): Linear(in_features=100, out_features=2048, bias=True)\n",
              "          (dropout): Dropout(p=0.2, inplace=False)\n",
              "          (linear2): Linear(in_features=2048, out_features=100, bias=True)\n",
              "          (norm1): LayerNorm((100,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm2): LayerNorm((100,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm3): LayerNorm((100,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout1): Dropout(p=0.2, inplace=False)\n",
              "          (dropout2): Dropout(p=0.2, inplace=False)\n",
              "          (dropout3): Dropout(p=0.2, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (norm): LayerNorm((100,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "  )\n",
              "  (decoder): Embedding(18671, 100)\n",
              "  (fc): Linear(in_features=100, out_features=18671, bias=True)\n",
              "  (logsoftmax): LogSoftmax()\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aXV_hSissPD8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model(trainloader, trans, lr=0.001, mom=0.9):\n",
        "    \n",
        "    loss_fn = nn.NLLLoss()\n",
        "    trans_optimiser = optim.SGD(trans.parameters(), lr=lr, momentum=mom)\n",
        "    \n",
        "    max_epochs = 100\n",
        "    old_loss = np.inf\n",
        "    \n",
        "    for epoch in range(max_epochs):\n",
        "        \n",
        "        running_loss = 0.0\n",
        "    \n",
        "        for i in trainloader:\n",
        "            \n",
        "            loss_val = 0\n",
        "            i[0] = i[0].type(torch.LongTensor)   # batch_size x Ts\n",
        "            i[1] = i[1].type(torch.LongTensor)   # batch_size x Tt\n",
        "            source_batch = i[0].to(device)\n",
        "            target_batch = i[1].to(device)\n",
        "\n",
        "            output = trans(source_batch, target_batch)  # Tt x batch_size x target_vocab_size\n",
        "\n",
        "            # calculating loss for the batch\n",
        "            for j in range(output.shape[1]):\n",
        "                logprobs = output[:, j, :].squeeze(1)\n",
        "                target_classes = target_batch[j].squeeze(0)\n",
        "                # inputs to NLL Loss should be of sizes Tt x n_classes and Tt\n",
        "                loss_val += loss_fn(logprobs, target_classes)\n",
        "\n",
        "            loss_val.backward()\n",
        "\n",
        "            nn.utils.clip_grad_norm_(trans.parameters(), 0.5)\n",
        "            trans_optimiser.step()\n",
        "            \n",
        "            running_loss += loss_val.item()\n",
        "        \n",
        "        print('Epoch', epoch+1, ': Loss =', running_loss)\n",
        "        \n",
        "        if abs(running_loss-old_loss)/running_loss < 1e-3:\n",
        "            print('Converged')\n",
        "            break\n",
        "            \n",
        "        old_loss = running_loss\n",
        "    \n",
        "    print('Finished Training')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eATQ5F12sPEA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainloader, testloader = train_test_loader(X_train, Y_train, X_test, Y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j7ekRPmVsPEG",
        "colab_type": "code",
        "colab": {},
        "outputId": "e8ce618d-e234-4f2a-a2ac-c7bad238fc9b"
      },
      "source": [
        "train_model(trainloader, trans_model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-64-8e3b99c66b7d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrans_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;32m<ipython-input-63-cfa52643b637>\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(trainloader, trans, lr, mom)\u001b[0m\n\u001b[0;32m     28\u001b[0m                 \u001b[0mloss_val\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogprobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_classes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m             \u001b[0mloss_val\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m             \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrans\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\users\\vasistha singhal\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    196\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m         \"\"\"\n\u001b[1;32m--> 198\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    199\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\users\\vasistha singhal\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m     99\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R5jnYdUrsPEJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}